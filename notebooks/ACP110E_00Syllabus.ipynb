{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ACP110E_00Syllabus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 110-2 W0 Syllabus\n",
        "__Advanced Computer Programming in Python__\n",
        "\n"
      ],
      "metadata": {
        "id": "qB57djOIXRSM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Course Schedule\n",
        "* W1-課程介紹/Introduction\n",
        "* W2-Python urllib \n",
        "* W3-BeautifulSoup\n",
        "* W4-Web Crawlers\n",
        "* W5-Scrapy\n",
        "* W6-Storing Data\n",
        "* W7-Flask Routes\n",
        "* W8-Jinja template \n",
        "* W9-Midterm presentation\n",
        "* W10-Flask-Mail\n",
        "* W11-REST API\n",
        "* W12-AWS Lambda + S3 (1) \n",
        "* W13-AWS Lambda + S3 (1)\n",
        "* W14-AWS Glue Data \n",
        "* W15-AWS Step Functions\n",
        "* W16-AWS Elastic Beanstalk\n",
        "* W17-Sample app-Book Recommender \n",
        "* W18-Final presentation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EqhFHnRdIO5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference books (O’Reilly Media)\n",
        "\n",
        "* Web Scraping with Python (Second Edition)-Collecting More Data from the Modern Web by Ryan Mitchell\n",
        "![Web Scraping with Python](https://kbimages1-a.akamaihd.net/b08563e1-d7e3-4a87-9115-225f270d0441/353/569/90/False/web-scraping-with-python-3.jpg)\n",
        "\n",
        "英文版: https://www.oreilly.com/library/view/web-scraping-with/9781491985564/\n",
        "\n",
        "中文版: https://www.tenlong.com.tw/products/9789864769261\n",
        "\n",
        "Github: https://github.com/REMitchell/python-scraping\n",
        "\n",
        "* Flask Web Development(Second Edition): Developing Web Applications With Python by Grinberg, \n",
        "![Flask Web Development](https://im2.book.com.tw/image/getImage?i=https://www.books.com.tw/img/F01/410/81/F014108175.jpg&v=609a97b1&w=348&h=348)\n",
        "\n",
        "英文版: https://www.oreilly.com/library/view/flask-web-development/9781491991725/\n",
        "\n",
        "英文版: https://www.books.com.tw/products/F014108175\n",
        "\n",
        "中文版: https://www.books.com.tw/products/0010793455\n",
        "\n",
        "Github: https://github.com/miguelgrinberg/flasky\n"
      ],
      "metadata": {
        "id": "uP9m_r8WCGY7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Web Scraping with Python \n",
        "* 第一部 建構擷取程序\n",
        "** 第一章 你的第一個擷取程序\n",
        "** 第二章 進階HTML解析\n",
        "** 第三章 撰寫網站爬行程序\n",
        "** 第四章 網站爬行模型\n",
        "** 第五章 Scrapy\n",
        "** 第六章 儲存資料\n",
        "* 第二部 儲存資料\n",
        "** 第七章 讀取文件\n",
        "** 第八章 清理髒資料\n",
        "** 第九章 讀寫自然語言\n",
        "** 第十章 表單與登入\n",
        "** 第十一章 與擷取相關的JavaScript\n",
        "** 第十二章 透過API 爬行\n",
        "** 第十三章 影像處理與文字辨識\n",
        "** 第十四章 避開擷取陷阱\n",
        "** 第十五章 以爬行程序測試你的網站\n",
        "** 第十六章 平行擷取網站\n",
        "** 第十七章 遠端擷取\n",
        "** 第十八章 網站擷取的法規與道德"
      ],
      "metadata": {
        "id": "a-cmjm2qsFSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reference webpages\n"
      ],
      "metadata": {
        "id": "I6Ty-C7dFhMv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1-Web scraping &  web crawler\n",
        "\n",
        "Web scraping is a computer software technology that obtains page content from web pages. Normal human access is usually simulated by software using a low-level hypertext transfer protocol.\n",
        "A web crawler is a web robot used to automatically browse the World Wide Web. Web crawlers can store the pages they access so that search engines can later generate indexes for users to search. The process of crawlers accessing the website will consume the target system resources. Many network systems do not allow crawlers to work by default. Therefore, when accessing a large number of pages, crawlers need to consider planning, load, and \"politeness\". Public sites that are unwilling to be accessed by crawlers and known to the crawler owner can use methods such as robots.txt files to avoid access. This file can ask the bot to index only a portion of the site, or not process it at all.\n",
        "\n",
        "Web scraping is data scraping used for extracting data from websites."
      ],
      "metadata": {
        "id": "DRGGMjkB5cZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2-Web apps with Flask\n",
        "\n",
        "Use the Python microframework Flask and use your creativity to build web applications! With the complete app developed by author Miguel Grinberg, you will learn Flask from the basics. The fully revised second edition incorporates important technical evolutions from the past three years.\n",
        "\n",
        "\n",
        "You can learn the core functionality of the framework and extend your app with advanced networking techniques such as database migrations and APIs. This book will introduce the topic and background in the first part of each chapter, and walk you through it in the second part.\n",
        "\n",
        " \n",
        "Contains three parts:\n",
        "\n",
        "* Introduce Flask in detail: Explain the basic knowledge of developing web apps with Flask, and the app architecture suitable for medium and large apps\n",
        "\n",
        "* Building Flasky: Step-by-step instructions on how to reuse templates, paginate lists, and use rich text to build an open-source blogging app\n",
        "\n",
        "* The last mile: A deep dive into unit testing strategies, profiling techniques, and deployment options for Flask apps"
      ],
      "metadata": {
        "id": "AmraskNsEZ5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flask Web Development : Developing Web Applications with Python\n",
        "* The first part introduces Flask in detail\n",
        "** Chapter 1 Installation\n",
        "** Chapter 2 Basic Application Structure\n",
        "** Chapter 3 Templates\n",
        "** Chapter 4 Web Forms\n",
        "** Chapter 5 Databases\n",
        "** Chapter 6 Email\n",
        "** Chapter 7 Large Application structure\n",
        "* Part 2 Example: Community Blog Application\n",
        "** Chapter 8 User Authentication\n",
        "** Chapter 9 User Roles\n",
        "** Chapter 10 User Profiles\n",
        "** Chapter 11 Blog Posts\n",
        "** Chapter 12 Followers\n",
        "** Chapter 13 User Comments\n",
        "** Chapter 14 Application Development Interface\n",
        "* Part 3 The Last Mile\n",
        "** Chapter 15 Testing\n",
        "** Chapter 16 Performance\n",
        "** Chapter 17 Deployment\n",
        "** Chapter 18 Additional Resources"
      ],
      "metadata": {
        "id": "9BOwfZ2QHqRi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3-AWS Scaling up a Serverless Web Crawler\n",
        "\n",
        "https://aws.amazon.com/tw/blogs/architecture/scaling-up-a-serverless-web-crawler-and-search-engine/\n",
        "\n",
        "![Serverless Web Crawler](https://d2908q01vomqb2.cloudfront.net/fc074d501302eb2b93e2554793fcaf50b3bf7291/2021/02/15/fig3-overall-architecture.png)\n"
      ],
      "metadata": {
        "id": "NBZ0ioH53yhS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AWS references\n",
        "\n",
        "* Build and automate a modern serverless data lake on AWS\n",
        "https://aws.amazon.com/tw/blogs/big-data/build-and-automate-a-serverless-data-lake-using-an-aws-glue-trigger-for-the-data-catalog-and-etl-jobs/\n",
        "\n"
      ],
      "metadata": {
        "id": "9vEAzvly4LKz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tools\n",
        "* PythonAnywhere: Host, run, and code Python in the cloud\n",
        " > https://www.pythonanywhere.com/\n",
        "* AWS\n",
        " > https://aws.amazon.com/tw/free/\n",
        "* AWS academy\n",
        " > https://www.awsacademy.com/LMS_Login"
      ],
      "metadata": {
        "id": "P0zA9KrIJKPU"
      }
    }
  ]
}